{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data to X_train, X_val, X_test, Y_train, Y_val, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDf(df, non_X_cols = ['Unnamed: 0','Date','Bond','Return_PD']):\n",
    "\n",
    "    # normalize all columns which is not in non_X_cols to -1 and 1\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "    n_rows = 35\n",
    "    n_groups = df.shape[0] // n_rows\n",
    "\n",
    "    # Iterate over the groups\n",
    "    for i in range(n_groups):\n",
    "        # Get the start and end index of the group\n",
    "        start_idx = i*n_rows\n",
    "        end_idx = (i+1)*n_rows\n",
    "        group_rows = df.iloc[start_idx:end_idx]\n",
    "    \n",
    "        # Scale the columns of the group\n",
    "        for col in group_rows.columns:\n",
    "            if col not in non_X_cols:\n",
    "                group_rows[col] = scaler.fit_transform(group_rows[[col]])\n",
    "        df.iloc[start_idx:end_idx] = group_rows\n",
    "\n",
    "\n",
    "    # get the unique dates of df_cleaned column: Date\n",
    "    dates = df['Date'].unique()\n",
    "    middleDate = dates[round(0.5 * len(dates))]\n",
    "    seventypercentileDate = dates[round(0.7 * len(dates))]\n",
    "\n",
    "        # get data until middleDate of df_cleaned\n",
    "    df_train = df[df['Date'] < middleDate]\n",
    "    # get data from middleDate of df_cleaned\n",
    "    df_val = df[df['Date'] >= middleDate]\n",
    "    df_val = df_val[df_val['Date'] < seventypercentileDate]\n",
    "    # get data from seventypercentileDate of df_cleaned\n",
    "    df_test = df[df['Date'] >= seventypercentileDate]\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorX(X):\n",
    "    X_4factor = X[['Momentum_2_12', 'Pickup', 'Yield', '401_%YoY', 'Beta']]\n",
    "    X_4factor['Yield'] = X_4factor['Yield'] - X_4factor['401_%YoY']\n",
    "    X_4factor = X_4factor.drop(columns = ['401_%YoY'])\n",
    "    return X_4factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitToXY(df, factor, non_X_cols = ['Unnamed: 0','Date','Bond','Return_PD']):\n",
    "\n",
    "    if (factor == True):\n",
    "        X = np.zeros((len(df), 4))\n",
    "    else:\n",
    "        X = np.zeros((len(df), 85))\n",
    "    Y = np.zeros((len(df), 1))\n",
    "    \n",
    "    df_X = df.drop(columns= non_X_cols)\n",
    "    df_Y = df['Return_PD']\n",
    "\n",
    "    if (factor == True):\n",
    "        df_X = factorX(df_X)\n",
    "\n",
    "    # Assign df_X to X\n",
    "    for i in range(len(df_X)):\n",
    "        X[i] = df_X.iloc[i].values\n",
    "        Y[i] = df_Y.iloc[i]\n",
    "        \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitAll(df, factor = False):\n",
    "    df_train, df_val, df_test = splitDf(df)\n",
    "    X_train, Y_train = splitToXY(df_train, factor)\n",
    "    X_val, Y_val = splitToXY(df_val, factor)\n",
    "    X_test, Y_test = splitToXY(df_test, factor)\n",
    "\n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonds names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bondsNames(df):\n",
    "    df_bonds = df['Bond'][:35]\n",
    "    return df_bonds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(Y_pred, Y_test):\n",
    "    \n",
    "    # R squared score\n",
    "    r2_test = r2_score(Y_test, Y_pred)\n",
    "    \n",
    "    return r2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuned_model(X_train, Y_train, X_val, Y_val, modelname, params):\n",
    "\n",
    "    r2_score = -100\n",
    "    best_model = None\n",
    "\n",
    "    if modelname == 'OLS':\n",
    "        best_model = LinearRegression()\n",
    "        best_model.fit(X_train, Y_train.ravel())\n",
    "\n",
    "    if modelname == 'Elastic':\n",
    "        for alpha in params['alpha']:\n",
    "            for l1 in params['l1_ratio']:\n",
    "                model = ElasticNet(alpha = alpha, l1_ratio = l1)\n",
    "                model.fit(X_train, Y_train.ravel())\n",
    "                Y_pred = model.predict(X_val)\n",
    "                r2_test = evaluate_model(Y_pred, Y_val)\n",
    "                if r2_test > r2_score:\n",
    "                    r2_score = r2_test\n",
    "                    best_model = model\n",
    "\n",
    "    if modelname == 'GLM':\n",
    "        best_model = LinearRegression()\n",
    "        best_model.fit(X_train, Y_train.ravel())\n",
    "\n",
    "    if modelname == 'RF':\n",
    "        for depth in params['max_depth']:\n",
    "            for features in params['max_features']:\n",
    "                model = RandomForestRegressor(max_depth = int(depth), n_estimators = 300, max_features = int(features))\n",
    "                model.fit(X_train, Y_train.ravel())\n",
    "                Y_pred = model.predict(X_val)\n",
    "                r2_test = evaluate_model(Y_pred, Y_val)\n",
    "                if r2_test > r2_score:\n",
    "                    r2_score = r2_test\n",
    "                    best_model = model\n",
    "\n",
    "\n",
    "    if modelname == 'XGB':\n",
    "        for depth in params['max_depth']:\n",
    "            for n_estimator in params['n_estimators']:\n",
    "                for lr in params['learning_rate']:\n",
    "                    model = XGBRegressor(max_depth = int(depth), n_estimators = int(n_estimator), learning_rate = lr)\n",
    "                    model.fit(X_train, Y_train.ravel())\n",
    "                    Y_pred = model.predict(X_val)\n",
    "                    r2_test = evaluate_model(Y_pred, Y_val)\n",
    "                    if r2_test > r2_score:\n",
    "                        r2_score = r2_test\n",
    "                        best_model = model\n",
    "\n",
    "    if modelname == 'SVM':\n",
    "        for c in params['C']:\n",
    "            for gamma in params['gamma']:\n",
    "                for kernel in params['kernel']:\n",
    "                    model = SVR(C = c, gamma = gamma, kernel = kernel)\n",
    "                    model.fit(X_train, Y_train.ravel())\n",
    "                    Y_pred = model.predict(X_val)\n",
    "                    r2_test = evaluate_model(Y_pred, Y_val)\n",
    "                    if r2_test > r2_score:\n",
    "                        r2_score = r2_test\n",
    "                        best_model = model\n",
    "\n",
    "    if modelname == 'NN':\n",
    "        for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "            for activation in params['activation']:\n",
    "                for solver in params['solver']:\n",
    "                    for learning_rate_init in params['learning_rate_init']:\n",
    "                        for alpha in params['alpha']:\n",
    "                            for batch_size in params['batch_size']:\n",
    "                                for learning_rate in params['learning_rate']:\n",
    "                                    for max_iter in params['max_iter']:\n",
    "                                        model = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes, activation = activation, solver = solver, learning_rate_init = learning_rate_init, alpha = alpha, batch_size = batch_size, learning_rate = learning_rate, max_iter = max_iter)\n",
    "                                        model.fit(X_train, Y_train)\n",
    "                                        Y_pred = model.predict(X_val)\n",
    "                                        r2_test = evaluate_model(Y_pred, Y_val)\n",
    "                                        if r2_test > r2_score:\n",
    "                                            r2_score = r2_test\n",
    "                                            best_model = model\n",
    "\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X_train, Y_train, X_val, Y_val, X_test, Y_test, modelname, params):\n",
    "\n",
    "    model = tuned_model(X_train, Y_train, X_val, Y_val, modelname = modelname, params = params)\n",
    "    counter = 0\n",
    "    Y_pred = np.zeros(Y_test.shape[0])\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "        Y_pred[i] = model.predict(X_test[i].reshape(1, -1))\n",
    "\n",
    "        counter += 1\n",
    "        if counter % (1*35) == 0:\n",
    "            X_train = np.concatenate((X_train, X_val[:i]), axis=0)\n",
    "            Y_train = np.concatenate((Y_train, Y_val[:i]), axis=0)\n",
    "            X_val = X_val[i:]\n",
    "            X_val = np.concatenate((X_val, X_test[:i]), axis=0)\n",
    "            Y_val = Y_val[i:]\n",
    "            Y_val = np.concatenate((Y_val, Y_test[:i]), axis=0)\n",
    "            model = tuned_model(X_train, Y_train, X_val, Y_val, modelname = modelname, params = params)\n",
    "\n",
    "            # print percentage of run time\n",
    "            print('Percentage of run time: ', round(counter/len(X_test)*100, 2), '%')\n",
    "\n",
    "    r2_test = evaluate_model(Y_pred, Y_test)\n",
    "    print('R2 score: ', r2_test)\n",
    "\n",
    "    return Y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "db35a02fd5d0ba4c5963f2cd8d92bdb63f7f3bde1f98582f1ef84023082d273b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
